{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd552f78",
   "metadata": {},
   "source": [
    "# PART 3: Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c231e2c3",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## C Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b104202",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Greg\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (63) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 59307\n",
      "Testing set size: 19769\n",
      "\n",
      "Num Possible Features: 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Greg\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# needs hyperparameters\n",
    "def lgbm_mod(): return LGBMRegressor(random_state = 1, n_estimators = 1000, learning_rate = 0.01, n_jobs = -1)\n",
    "\n",
    "working_directory = 'D:/machine_learning/DFS/NHL/'\n",
    "os.chdir(working_directory)\n",
    "data_dir = 'Data/' #Where is your data located?\n",
    "etl_dir = 'Data/ETL/' #Where is your output data going?\n",
    "\n",
    "player_stats = pd.read_csv('Data/alldata_2016-2022.csv', index_col = 0) #Read In Our Main Dataset\n",
    "c_df = pd.read_csv(etl_dir + 'c_stats.csv', index_col = 0)\n",
    "\n",
    "# ordinal encode HomeorAway column\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "encoder = OrdinalEncoder()\n",
    "c_df['HomeOrAway'] = encoder.fit_transform(c_df['HomeOrAway'].to_numpy().reshape(-1, 1))\n",
    "\n",
    "c_df = c_df.rename(columns={'Team_x' : 'Team'})\n",
    "\n",
    "# convert date from object dtype to datetime\n",
    "c_df['Date'] = pd.to_datetime(c_df['Date'], format = '%Y%m%d')\n",
    "c_df['Date'] = c_df['Date'].dt.strftime('%Y%m%d')\n",
    "\n",
    "#C DK PTS Rank For The Given Season & Date Pair\n",
    "c_df['Act_C_FPRank'] = c_df.groupby(['Season','Date'])['FantasyPointsFanDuel'].rank(method='min', ascending = False)\n",
    "\n",
    "#Columns We Want To Add To Dataset\n",
    "keep_cols = ['Season','Date','Name','Act_C_FPRank']\n",
    "\n",
    "#Make sure we have no duplicated columns or infinity errors\n",
    "c_df = c_df.loc[:,~c_df.columns.duplicated()]\n",
    "c_df= c_df.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "#Columns We Can't Include In Our Features Datasets\n",
    "dcols = ['TeamID', 'PlayerID', 'Team', 'Position', 'Games', 'Started', \n",
    "         'Goals', 'Assists', 'Points', 'PlusMinus', 'HatTricks',\n",
    "       'PenaltyMinutes', 'PowerPlayGoals', 'ShortHandedGoals', 'ShotsOnGoal',\n",
    "       'Blocks',\n",
    "       'Month', 'Year'\n",
    "]\n",
    "\n",
    "\n",
    "# g_vs_act.drop_duplicates(subset=['Player', 'Date'], keep='first', inplace = True, ignore_index = True)\n",
    "\n",
    "X = c_df.drop(dcols, axis = 1)\n",
    "Y = c_df['FantasyPointsFanDuel']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Create Training and Testing DataSets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.25, random_state=42)\n",
    "\n",
    "X_train.reset_index(inplace = True, drop=True)\n",
    "X_test.reset_index(inplace = True, drop=True)\n",
    "Y_train.reset_index(inplace = True, drop=True)\n",
    "Y_test.reset_index(inplace = True, drop=True)\n",
    "\n",
    "print('Training set size:', len(X_train))\n",
    "print('Testing set size:', len(X_test))\n",
    "\n",
    "pred_df = pd.concat([X_test, Y_test], axis = 1)\n",
    "\n",
    "more_dcols = ['Season', 'Date', 'Name', 'Opponent', 'FantasyPointsFanDuel', 'Act_C_FPRank']\n",
    "\n",
    "X_train.drop(more_dcols, axis = 1, inplace = True)\n",
    "X_test.drop(more_dcols, axis = 1, inplace = True)\n",
    "\n",
    "# dump non-scaled train df for external scaling to work\n",
    "filename = 'scalers/c_X_train.pkl'\n",
    "joblib.dump(X_train, filename)\n",
    "\n",
    "# Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "c_scaler = StandardScaler().fit(X_train)\n",
    "X_train = pd.DataFrame(c_scaler.transform(X_train), columns = X_train.columns)\n",
    "X_test = pd.DataFrame(c_scaler.transform(X_test), columns = X_test.columns)\n",
    "filename = 'scalers/c_scaler.pkl'\n",
    "joblib.dump(c_scaler, filename)\n",
    "\n",
    "print('\\nNum Possible Features:',len(X_train.columns.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6180d764",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "possible features: ['HomeOrAway', 'GM3', 'GM_pg3', 'G3', 'G_pg3', 'A3', 'A_pg3', 'PTS3', 'PTS_pg3', 'plusminus3', 'plusminus_pg3', 'HT3', 'HT_pg3', 'PIM3', 'PIM_pg3', 'PPG3', 'PPG_pg3', 'SHG3', 'SHG_pg3', 'SOG3', 'SOG_pg3', 'BLK3', 'BLK_pg3', 'FP3', 'FP_pg3', 'GM', 'G', 'G_pg', 'A', 'A_pg', 'PTS', 'PTS_pg', 'PM', 'PM_pg', 'HT', 'HT_pg', 'PIM', 'PIM_pg', 'PPG', 'PPG_pg', 'SHG_pg', 'SOG', 'SOG_pg', 'BLK', 'BLK_pg', 'FP', 'FP_pg', 'def_G3', 'def_G_pg3', 'def_A3', 'def_A_pg3', 'def_PTS3', 'def_PTS_pg3', 'def_plusminus3', 'def_plusminus_pg3', 'def_HT3', 'def_HT_pg3', 'def_PIM3', 'def_PIM_pg3', 'def_PPG3', 'def_PPG_pg3', 'def_SHG3', 'def_SHG_pg3', 'def_SOG3', 'def_SOG_pg3', 'def_BLK3', 'def_BLK_pg3', 'def_FP3', 'def_FP_pg3', 'def_G', 'def_G_pg', 'def_A', 'def_A_pg', 'def_PTS', 'def_PTS_pg', 'def_PM', 'def_PM_pg', 'def_HT', 'def_HT_pg', 'def_PIM', 'def_PIM_pg', 'def_PPG', 'def_PPG_pg', 'def_SHG_pg', 'def_SOG', 'def_SOG_pg', 'def_BLK', 'def_BLK_pg', 'def_FP', 'def_FP_pg'] \n",
      "\n",
      "T50 features ['SOG_pg', 'FP_pg', 'PM_pg', 'FP3', 'PPG_pg', 'A_pg', 'def_SOG_pg', 'def_FP3', 'SOG', 'BLK_pg', 'SOG3', 'PIM_pg', 'G_pg', 'def_BLK_pg', 'def_PM_pg', 'FP', 'FP_pg3', 'def_PIM_pg', 'def_A_pg', 'PTS_pg', 'def_PIM', 'PM', 'def_SOG', 'def_G_pg', 'def_PM', 'A', 'def_FP_pg', 'HomeOrAway', 'BLK', 'def_FP', 'HT_pg', 'PIM', 'def_BLK', 'def_PTS_pg', 'def_A', 'plusminus3', 'def_SOG3', 'def_PPG_pg', 'def_PTS', 'SOG_pg3', 'PTS', 'def_plusminus3', 'G', 'GM_pg3', 'def_PIM3', 'def_G', 'def_FP_pg3', 'GM3', 'PPG', 'def_PPG'] \n",
      "\n",
      "T30 features ['SOG_pg', 'FP_pg', 'PM_pg', 'def_SOG_pg', 'FP3', 'A_pg', 'def_FP3', 'PPG_pg', 'BLK_pg', 'def_PM_pg', 'def_BLK_pg', 'SOG', 'PIM_pg', 'def_PIM_pg', 'def_A_pg', 'G_pg', 'SOG3', 'def_FP_pg', 'def_G_pg', 'FP', 'FP_pg3', 'PTS_pg', 'def_SOG', 'A', 'plusminus3', 'BLK', 'PM', 'def_BLK', 'HomeOrAway', 'def_PTS_pg'] \n",
      "\n",
      "T20 features ['SOG_pg', 'def_FP3', 'FP_pg', 'FP3', 'def_PM_pg', 'PM_pg', 'PPG_pg', 'def_SOG_pg', 'def_PIM_pg', 'A_pg', 'SOG3', 'SOG', 'def_A_pg', 'PIM_pg', 'BLK_pg', 'FP', 'def_BLK_pg', 'def_G_pg', 'def_SOG', 'G_pg'] \n",
      "\n",
      "T10 features ['PM_pg', 'def_SOG_pg', 'def_PIM_pg', 'A_pg', 'def_FP3', 'SOG', 'def_PM_pg', 'FP3', 'FP_pg', 'SOG_pg'] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all</td>\n",
       "      <td>5.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>5.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>5.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>5.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>5.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Features   MAE\n",
       "0      all  5.86\n",
       "1       50  5.86\n",
       "2       30  5.87\n",
       "3       20  5.88\n",
       "4       10  5.88"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" MODEL SELECTION \"\"\"\n",
    "\n",
    "model = lgbm_mod()\n",
    "\n",
    "\"\"\"                 \"\"\"\n",
    "\n",
    "#print possible features\n",
    "print('possible features:', X_train.columns.tolist(), '\\n')\n",
    "\n",
    "# Fit model, make predictions with all features\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "preds_all = model.predict(X_test)\n",
    "\n",
    "pdf = pred_df[['Season','Date','Opponent','Name','FantasyPointsFanDuel']].copy()\n",
    "\n",
    "pdf['Pred_FP_all'] = preds_all\n",
    "\n",
    "# save the initial model to disk\n",
    "filename = 'models/LGBM_models/C_model_allfeats.pkl'\n",
    "joblib.dump(model, filename) \n",
    "\n",
    "# get top 50 features\n",
    "dset = pd.DataFrame({'attr':X_train.columns.tolist(),'importance':model.feature_importances_}).sort_values(by='importance', ascending=False).reset_index(drop=True)\n",
    "attr50 = dset['attr'][0:50].tolist()\n",
    "\n",
    "# Using Top 50 Features, Find Top 30 Features\n",
    "model.fit(X_train[attr50], Y_train)\n",
    "dset = pd.DataFrame({'attr':X_train[attr50].columns.tolist(),'importance':model.feature_importances_}).sort_values(by='importance', ascending=False).reset_index(drop=True)\n",
    "attr30 = dset['attr'][0:30].tolist()\n",
    "\n",
    "# Using Top 30 Features, Find Top 20 Features\n",
    "model.fit(X_train[attr30], Y_train)\n",
    "dset = pd.DataFrame({'attr':X_train[attr30].columns.tolist(),'importance':model.feature_importances_}).sort_values(by='importance', ascending=False).reset_index(drop=True)\n",
    "attr20 = dset['attr'][0:20].tolist()\n",
    "\n",
    "#Perform RFE (recursive feature elimination) using Top 20 Features, To Find Top 15\n",
    "rfe_model = RFE(model, n_features_to_select = 10)\n",
    "rfe_model.fit(X_train[attr20], Y_train)\n",
    "dset = pd.DataFrame({'attr':X_train[attr20].columns.tolist(),'importance':rfe_model.ranking_}).sort_values(by='importance', ascending=False).reset_index(drop=True)\n",
    "cols10= dset[dset['importance']==1]['attr'].tolist()\n",
    "\n",
    "print('T50 features', attr50, '\\n')\n",
    "print('T30 features', attr30, '\\n')\n",
    "print('T20 features', attr20, '\\n')\n",
    "print('T10 features',cols10, '\\n')\n",
    "\n",
    "model.fit(X_train[attr50], Y_train)\n",
    "preds50 = model.predict(X_test[attr50])\n",
    "filename = 'models/LGBM_models/C_model_50feats.pkl'\n",
    "joblib.dump(model, filename) \n",
    "\n",
    "model.fit(X_train[attr30], Y_train)\n",
    "preds30 = model.predict(X_test[attr30])\n",
    "filename = 'models/LGBM_models/C_model_30feats.pkl'\n",
    "joblib.dump(model, filename) \n",
    "\n",
    "model.fit(X_train[attr20], Y_train)\n",
    "preds20 = model.predict(X_test[attr20])\n",
    "filename = 'models/LGBM_models/C_model_20feats.pkl'\n",
    "joblib.dump(model, filename) \n",
    "\n",
    "model.fit(X_train[cols10], Y_train)\n",
    "preds10 = model.predict(X_test[cols10])\n",
    "filename = 'models/LGBM_models/C_model_10feats.pkl'\n",
    "joblib.dump(model, filename) \n",
    "\n",
    "# pdf = pred_df[['Season','Week','Team','Defense','PlayerID','Name','Act_G_DKPtsRank','Act_G_DKPts']].copy()\n",
    "pdf['Pred_FP_50'] = preds50\n",
    "pdf['Pred_FP_30'] = preds30\n",
    "pdf['Pred_FP_20'] = preds20\n",
    "pdf['Pred_FP_10'] = preds10\n",
    "pdf.to_csv(etl_dir + 'c_predictions_lgbm_50_30_20_10.csv')\n",
    "\n",
    "feature_sets = ['all', '50', '30', '20', '10']\n",
    "\n",
    "mae_values = [\n",
    "    \"{:.2f}\".format(mean_absolute_error(Y_test, preds_all)),\n",
    "    \"{:.2f}\".format(mean_absolute_error(Y_test, preds50)),\n",
    "    \"{:.2f}\".format(mean_absolute_error(Y_test, preds30)),\n",
    "    \"{:.2f}\".format(mean_absolute_error(Y_test, preds20)),\n",
    "    \"{:.2f}\".format(mean_absolute_error(Y_test, preds10))\n",
    "]\n",
    "\n",
    "results_df = pd.DataFrame({'Features' : feature_sets, 'MAE' : mae_values})\n",
    "\n",
    "results_df.style.hide_index()\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80d3ae1a",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>FantasyPointsFanDuel</th>\n",
       "      <th>FantasyPointsFanDuel</th>\n",
       "      <th>Pred_FP_all</th>\n",
       "      <th>Pred_FP_50</th>\n",
       "      <th>Pred_FP_30</th>\n",
       "      <th>Pred_FP_20</th>\n",
       "      <th>Pred_FP_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>J.T. Miller</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>7.688846</td>\n",
       "      <td>7.630887</td>\n",
       "      <td>7.670751</td>\n",
       "      <td>7.906294</td>\n",
       "      <td>7.290532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reid Boucher</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.683440</td>\n",
       "      <td>3.764972</td>\n",
       "      <td>4.130186</td>\n",
       "      <td>4.074728</td>\n",
       "      <td>4.066100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Noah Gregor</td>\n",
       "      <td>13.6</td>\n",
       "      <td>13.6</td>\n",
       "      <td>3.803863</td>\n",
       "      <td>3.811769</td>\n",
       "      <td>3.554098</td>\n",
       "      <td>3.569678</td>\n",
       "      <td>3.673112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sidney Crosby</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>21.151927</td>\n",
       "      <td>22.625053</td>\n",
       "      <td>23.908379</td>\n",
       "      <td>21.425370</td>\n",
       "      <td>22.462075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Patrick Marleau</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>7.712842</td>\n",
       "      <td>7.707133</td>\n",
       "      <td>7.388110</td>\n",
       "      <td>7.255552</td>\n",
       "      <td>6.958360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19764</th>\n",
       "      <td>Eric Staal</td>\n",
       "      <td>23.7</td>\n",
       "      <td>23.7</td>\n",
       "      <td>9.565264</td>\n",
       "      <td>9.236853</td>\n",
       "      <td>9.412636</td>\n",
       "      <td>9.804759</td>\n",
       "      <td>8.678860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19765</th>\n",
       "      <td>Brock Nelson</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>7.855819</td>\n",
       "      <td>7.850587</td>\n",
       "      <td>7.852205</td>\n",
       "      <td>7.197587</td>\n",
       "      <td>7.222626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19766</th>\n",
       "      <td>Travis Boyd</td>\n",
       "      <td>9.6</td>\n",
       "      <td>9.6</td>\n",
       "      <td>4.652252</td>\n",
       "      <td>4.475292</td>\n",
       "      <td>4.253412</td>\n",
       "      <td>4.358835</td>\n",
       "      <td>4.281073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19767</th>\n",
       "      <td>Tyler Seguin</td>\n",
       "      <td>6.4</td>\n",
       "      <td>6.4</td>\n",
       "      <td>13.021267</td>\n",
       "      <td>12.577750</td>\n",
       "      <td>13.322414</td>\n",
       "      <td>15.065061</td>\n",
       "      <td>14.942527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19768</th>\n",
       "      <td>Zach Aston-Reese</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>7.453524</td>\n",
       "      <td>7.372074</td>\n",
       "      <td>7.527272</td>\n",
       "      <td>7.152994</td>\n",
       "      <td>7.095445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19769 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Name  FantasyPointsFanDuel  FantasyPointsFanDuel  \\\n",
       "0           J.T. Miller                   1.6                   1.6   \n",
       "1          Reid Boucher                   0.0                   0.0   \n",
       "2           Noah Gregor                  13.6                  13.6   \n",
       "3         Sidney Crosby                   3.2                   3.2   \n",
       "4       Patrick Marleau                   3.2                   3.2   \n",
       "...                 ...                   ...                   ...   \n",
       "19764        Eric Staal                  23.7                  23.7   \n",
       "19765      Brock Nelson                   1.6                   1.6   \n",
       "19766       Travis Boyd                   9.6                   9.6   \n",
       "19767      Tyler Seguin                   6.4                   6.4   \n",
       "19768  Zach Aston-Reese                   1.6                   1.6   \n",
       "\n",
       "       Pred_FP_all  Pred_FP_50  Pred_FP_30  Pred_FP_20  Pred_FP_10  \n",
       "0         7.688846    7.630887    7.670751    7.906294    7.290532  \n",
       "1         3.683440    3.764972    4.130186    4.074728    4.066100  \n",
       "2         3.803863    3.811769    3.554098    3.569678    3.673112  \n",
       "3        21.151927   22.625053   23.908379   21.425370   22.462075  \n",
       "4         7.712842    7.707133    7.388110    7.255552    6.958360  \n",
       "...            ...         ...         ...         ...         ...  \n",
       "19764     9.565264    9.236853    9.412636    9.804759    8.678860  \n",
       "19765     7.855819    7.850587    7.852205    7.197587    7.222626  \n",
       "19766     4.652252    4.475292    4.253412    4.358835    4.281073  \n",
       "19767    13.021267   12.577750   13.322414   15.065061   14.942527  \n",
       "19768     7.453524    7.372074    7.527272    7.152994    7.095445  \n",
       "\n",
       "[19769 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf[['Name', 'FantasyPointsFanDuel', 'Pred_FP_all', 'Pred_FP_50', 'Pred_FP_30', 'Pred_FP_20', 'Pred_FP_10']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c40930e",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## W Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1d4e339",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Greg\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (63) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 60550\n",
      "Testing set size: 20184\n",
      "\n",
      "Num Possible Features: 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Greg\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# needs hyperparameters\n",
    "def lgbm_mod(): return LGBMRegressor(random_state = 1, n_estimators = 1000, learning_rate = 0.01, n_jobs = -1)\n",
    "\n",
    "working_directory = 'D:/machine_learning/DFS/NHL/'\n",
    "os.chdir(working_directory)\n",
    "data_dir = 'Data/' #Where is your data located?\n",
    "etl_dir = 'Data/ETL/' #Where is your output data going?\n",
    "\n",
    "player_stats = pd.read_csv('Data/alldata_2016-2022.csv', index_col = 0) #Read In Our Main Dataset\n",
    "w_df = pd.read_csv(etl_dir + 'w_stats.csv', index_col = 0)\n",
    "\n",
    "# ordinal encode HomeorAway column\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "encoder = OrdinalEncoder()\n",
    "w_df['HomeOrAway'] = encoder.fit_transform(w_df['HomeOrAway'].to_numpy().reshape(-1, 1))\n",
    "\n",
    "w_df = w_df.rename(columns={'Team_x' : 'Team'})\n",
    "\n",
    "# convert date from object dtype to datetime\n",
    "w_df['Date'] = pd.to_datetime(w_df['Date'], format = '%Y%m%d')\n",
    "w_df['Date'] = w_df['Date'].dt.strftime('%Y%m%d')\n",
    "\n",
    "#W DK PTS Rank For The Given Season & Date Pair\n",
    "w_df['Act_W_FPRank'] = w_df.groupby(['Season','Date'])['FantasyPointsFanDuel'].rank(method='min', ascending = False)\n",
    "\n",
    "#Columns We Want To Add To Dataset\n",
    "keep_cols = ['Season','Date','Name','Act_W_FPRank']\n",
    "\n",
    "#Make sure we have no duplicated columns or infinity errors\n",
    "w_df = w_df.loc[:,~w_df.columns.duplicated()]\n",
    "w_df= w_df.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "#Columns We Can't Include In Our Features Datasets\n",
    "dcols = ['TeamID', 'PlayerID', 'Team', 'Position', 'Games', 'Started', \n",
    "         'Goals', 'Assists', 'Points', 'PlusMinus', 'HatTricks',\n",
    "       'PenaltyMinutes', 'PowerPlayGoals', 'ShortHandedGoals', 'ShotsOnGoal',\n",
    "       'Blocks',\n",
    "       'Month', 'Year'\n",
    "]\n",
    "\n",
    "\n",
    "# g_vs_act.drop_duplicates(subset=['Player', 'Date'], keep='first', inplace = True, ignore_index = True)\n",
    "\n",
    "X = w_df.drop(dcols, axis = 1)\n",
    "Y = w_df['FantasyPointsFanDuel']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Create Training and Testing DataSets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.25, random_state=42)\n",
    "\n",
    "X_train.reset_index(inplace = True, drop=True)\n",
    "X_test.reset_index(inplace = True, drop=True)\n",
    "Y_train.reset_index(inplace = True, drop=True)\n",
    "Y_test.reset_index(inplace = True, drop=True)\n",
    "\n",
    "print('Training set size:', len(X_train))\n",
    "print('Testing set size:', len(X_test))\n",
    "\n",
    "pred_df = pd.concat([X_test, Y_test], axis = 1)\n",
    "\n",
    "more_dcols = ['Season', 'Date', 'Name', 'Opponent', 'FantasyPointsFanDuel', 'Act_W_FPRank']\n",
    "\n",
    "X_train.drop(more_dcols, axis = 1, inplace = True)\n",
    "X_test.drop(more_dcols, axis = 1, inplace = True)\n",
    "\n",
    "# dump non-scaled train df for external scaling to work\n",
    "filename = 'scalers/w_X_train.pkl'\n",
    "joblib.dump(X_train, filename)\n",
    "\n",
    "# Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "w_scaler = StandardScaler().fit(X_train)\n",
    "X_train = pd.DataFrame(w_scaler.transform(X_train), columns = X_train.columns)\n",
    "X_test = pd.DataFrame(w_scaler.transform(X_test), columns = X_test.columns)\n",
    "filename = 'scalers/w_scaler.pkl'\n",
    "joblib.dump(w_scaler, filename)\n",
    "\n",
    "print('\\nNum Possible Features:',len(X_train.columns.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d61b4d9",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "possible features: ['HomeOrAway', 'GM3', 'GM_pg3', 'G3', 'G_pg3', 'A3', 'A_pg3', 'PTS3', 'PTS_pg3', 'plusminus3', 'plusminus_pg3', 'HT3', 'HT_pg3', 'PIM3', 'PIM_pg3', 'PPG3', 'PPG_pg3', 'SHG3', 'SHG_pg3', 'SOG3', 'SOG_pg3', 'BLK3', 'BLK_pg3', 'FP3', 'FP_pg3', 'GM', 'G', 'G_pg', 'A', 'A_pg', 'PTS', 'PTS_pg', 'PM', 'PM_pg', 'HT', 'HT_pg', 'PIM', 'PIM_pg', 'PPG', 'PPG_pg', 'SHG_pg', 'SOG', 'SOG_pg', 'BLK', 'BLK_pg', 'FP', 'FP_pg', 'def_G3', 'def_G_pg3', 'def_A3', 'def_A_pg3', 'def_PTS3', 'def_PTS_pg3', 'def_plusminus3', 'def_plusminus_pg3', 'def_HT3', 'def_HT_pg3', 'def_PIM3', 'def_PIM_pg3', 'def_PPG3', 'def_PPG_pg3', 'def_SHG3', 'def_SHG_pg3', 'def_SOG3', 'def_SOG_pg3', 'def_BLK3', 'def_BLK_pg3', 'def_FP3', 'def_FP_pg3', 'def_G', 'def_G_pg', 'def_A', 'def_A_pg', 'def_PTS', 'def_PTS_pg', 'def_PM', 'def_PM_pg', 'def_HT', 'def_HT_pg', 'def_PIM', 'def_PIM_pg', 'def_PPG', 'def_PPG_pg', 'def_SHG_pg', 'def_SOG', 'def_SOG_pg', 'def_BLK', 'def_BLK_pg', 'def_FP', 'def_FP_pg'] \n",
      "\n",
      "T50 features ['SOG_pg', 'FP_pg', 'PM_pg', 'A_pg', 'FP3', 'def_BLK_pg', 'def_SOG_pg', 'def_PIM_pg', 'PPG_pg', 'SOG3', 'BLK_pg', 'PIM_pg', 'SOG', 'G_pg', 'PTS_pg', 'FP', 'def_PM_pg', 'A', 'FP_pg3', 'def_A_pg', 'def_FP3', 'def_SOG', 'def_PM', 'def_PIM', 'def_PPG_pg', 'def_G_pg', 'PM', 'def_FP_pg', 'BLK', 'HT_pg', 'def_FP', 'SOG_pg3', 'def_SOG3', 'PIM', 'HomeOrAway', 'PTS', 'def_BLK', 'GM_pg3', 'def_PTS_pg', 'G', 'def_PTS', 'def_plusminus3', 'def_BLK3', 'def_A', 'GM3', 'def_FP_pg3', 'def_G', 'plusminus3', 'def_PIM3', 'def_PPG'] \n",
      "\n",
      "T30 features ['SOG_pg', 'FP_pg', 'PM_pg', 'A_pg', 'FP3', 'def_BLK_pg', 'PPG_pg', 'def_PM_pg', 'G_pg', 'PIM_pg', 'def_SOG_pg', 'BLK_pg', 'def_PIM_pg', 'def_FP3', 'SOG', 'PTS_pg', 'def_A_pg', 'FP_pg3', 'SOG3', 'def_FP_pg', 'def_G_pg', 'A', 'def_PPG_pg', 'FP', 'def_SOG', 'HT_pg', 'def_SOG3', 'def_PIM', 'PM', 'SOG_pg3'] \n",
      "\n",
      "T20 features ['SOG_pg', 'FP3', 'FP_pg', 'def_FP3', 'PM_pg', 'def_PM_pg', 'A_pg', 'def_BLK_pg', 'PIM_pg', 'PPG_pg', 'BLK_pg', 'def_SOG_pg', 'def_A_pg', 'SOG', 'def_PIM_pg', 'def_FP_pg', 'def_G_pg', 'G_pg', 'def_SOG', 'FP_pg3'] \n",
      "\n",
      "T10 features ['def_BLK_pg', 'FP3', 'def_SOG_pg', 'SOG', 'def_PIM_pg', 'def_FP_pg', 'def_PM_pg', 'PM_pg', 'FP_pg', 'SOG_pg'] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all</td>\n",
       "      <td>5.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>5.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>5.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>5.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>5.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Features   MAE\n",
       "0      all  5.81\n",
       "1       50  5.81\n",
       "2       30  5.82\n",
       "3       20  5.83\n",
       "4       10  5.83"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" MODEL SELECTION \"\"\"\n",
    "\n",
    "model = lgbm_mod()\n",
    "\n",
    "\"\"\"                 \"\"\"\n",
    "\n",
    "#print possible features\n",
    "print('possible features:', X_train.columns.tolist(), '\\n')\n",
    "\n",
    "# Fit model, make predictions with all features\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "preds_all = model.predict(X_test)\n",
    "\n",
    "pdf = pred_df[['Season','Date','Opponent','Name','FantasyPointsFanDuel']].copy()\n",
    "\n",
    "pdf['Pred_FP_all'] = preds_all\n",
    "\n",
    "# save the initial model to disk\n",
    "filename = 'models/LGBM_models/W_model_allfeats.pkl'\n",
    "joblib.dump(model, filename) \n",
    "\n",
    "# get top 50 features\n",
    "dset = pd.DataFrame({'attr':X_train.columns.tolist(),'importance':model.feature_importances_}).sort_values(by='importance', ascending=False).reset_index(drop=True)\n",
    "attr50 = dset['attr'][0:50].tolist()\n",
    "\n",
    "# Using Top 50 Features, Find Top 30 Features\n",
    "model.fit(X_train[attr50], Y_train)\n",
    "dset = pd.DataFrame({'attr':X_train[attr50].columns.tolist(),'importance':model.feature_importances_}).sort_values(by='importance', ascending=False).reset_index(drop=True)\n",
    "attr30 = dset['attr'][0:30].tolist()\n",
    "\n",
    "# Using Top 30 Features, Find Top 20 Features\n",
    "model.fit(X_train[attr30], Y_train)\n",
    "dset = pd.DataFrame({'attr':X_train[attr30].columns.tolist(),'importance':model.feature_importances_}).sort_values(by='importance', ascending=False).reset_index(drop=True)\n",
    "attr20 = dset['attr'][0:20].tolist()\n",
    "\n",
    "#Perform RFE (recursive feature elimination) using Top 20 Features, To Find Top 15\n",
    "rfe_model = RFE(model, n_features_to_select = 10)\n",
    "rfe_model.fit(X_train[attr20], Y_train)\n",
    "dset = pd.DataFrame({'attr':X_train[attr20].columns.tolist(),'importance':rfe_model.ranking_}).sort_values(by='importance', ascending=False).reset_index(drop=True)\n",
    "cols10= dset[dset['importance']==1]['attr'].tolist()\n",
    "\n",
    "print('T50 features', attr50, '\\n')\n",
    "print('T30 features', attr30, '\\n')\n",
    "print('T20 features', attr20, '\\n')\n",
    "print('T10 features',cols10, '\\n')\n",
    "\n",
    "model.fit(X_train[attr50], Y_train)\n",
    "preds50 = model.predict(X_test[attr50])\n",
    "filename = 'models/LGBM_models/W_model_50feats.pkl'\n",
    "joblib.dump(model, filename) \n",
    "\n",
    "model.fit(X_train[attr30], Y_train)\n",
    "preds30 = model.predict(X_test[attr30])\n",
    "filename = 'models/LGBM_models/W_model_30feats.pkl'\n",
    "joblib.dump(model, filename) \n",
    "\n",
    "model.fit(X_train[attr20], Y_train)\n",
    "preds20 = model.predict(X_test[attr20])\n",
    "filename = 'models/LGBM_models/W_model_20feats.pkl'\n",
    "joblib.dump(model, filename) \n",
    "\n",
    "model.fit(X_train[cols10], Y_train)\n",
    "preds10 = model.predict(X_test[cols10])\n",
    "filename = 'models/LGBM_models/W_model_10feats.pkl'\n",
    "joblib.dump(model, filename) \n",
    "\n",
    "# pdf = pred_df[['Season','Week','Team','Defense','PlayerID','Name','Act_W_DKPtsRank','Act_W_DKPts']].copy()\n",
    "pdf['Pred_FP_50'] = preds50\n",
    "pdf['Pred_FP_30'] = preds30\n",
    "pdf['Pred_FP_20'] = preds20\n",
    "pdf['Pred_FP_10'] = preds10\n",
    "pdf.to_csv(etl_dir + 'w_predictions_lgbm_50_30_20_10.csv')\n",
    "\n",
    "feature_sets = ['all', '50', '30', '20', '10']\n",
    "\n",
    "mae_values = [\n",
    "    \"{:.2f}\".format(mean_absolute_error(Y_test, preds_all)),\n",
    "    \"{:.2f}\".format(mean_absolute_error(Y_test, preds50)),\n",
    "    \"{:.2f}\".format(mean_absolute_error(Y_test, preds30)),\n",
    "    \"{:.2f}\".format(mean_absolute_error(Y_test, preds20)),\n",
    "    \"{:.2f}\".format(mean_absolute_error(Y_test, preds10))\n",
    "]\n",
    "\n",
    "results_df = pd.DataFrame({'Features' : feature_sets, 'MAE' : mae_values})\n",
    "\n",
    "results_df.style.hide_index()\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1466f59",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>FantasyPointsFanDuel</th>\n",
       "      <th>FantasyPointsFanDuel</th>\n",
       "      <th>Pred_FP_all</th>\n",
       "      <th>Pred_FP_50</th>\n",
       "      <th>Pred_FP_30</th>\n",
       "      <th>Pred_FP_20</th>\n",
       "      <th>Pred_FP_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Timo Meier</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.589318</td>\n",
       "      <td>4.575845</td>\n",
       "      <td>4.591920</td>\n",
       "      <td>4.526959</td>\n",
       "      <td>4.153235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Martin Frk</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.896026</td>\n",
       "      <td>3.905810</td>\n",
       "      <td>3.799460</td>\n",
       "      <td>3.824853</td>\n",
       "      <td>3.882637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kyle Palmieri</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.464828</td>\n",
       "      <td>9.618115</td>\n",
       "      <td>10.613752</td>\n",
       "      <td>10.450582</td>\n",
       "      <td>11.093447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thomas Vanek</td>\n",
       "      <td>8.5</td>\n",
       "      <td>8.5</td>\n",
       "      <td>5.987462</td>\n",
       "      <td>5.989495</td>\n",
       "      <td>5.905314</td>\n",
       "      <td>6.307128</td>\n",
       "      <td>6.175032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kris Versteeg</td>\n",
       "      <td>22.1</td>\n",
       "      <td>22.1</td>\n",
       "      <td>6.858372</td>\n",
       "      <td>6.798116</td>\n",
       "      <td>6.809300</td>\n",
       "      <td>6.854523</td>\n",
       "      <td>6.390102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20179</th>\n",
       "      <td>Taylor Leier</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>6.178045</td>\n",
       "      <td>6.047882</td>\n",
       "      <td>6.284507</td>\n",
       "      <td>6.235827</td>\n",
       "      <td>5.942053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20180</th>\n",
       "      <td>Joonas Donskoi</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.988086</td>\n",
       "      <td>6.787917</td>\n",
       "      <td>6.698339</td>\n",
       "      <td>6.826358</td>\n",
       "      <td>6.923340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20181</th>\n",
       "      <td>Patrick Sharp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.755407</td>\n",
       "      <td>3.394232</td>\n",
       "      <td>2.919445</td>\n",
       "      <td>3.353604</td>\n",
       "      <td>3.599713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20182</th>\n",
       "      <td>Josh Bailey</td>\n",
       "      <td>11.7</td>\n",
       "      <td>11.7</td>\n",
       "      <td>9.769311</td>\n",
       "      <td>9.575595</td>\n",
       "      <td>9.769985</td>\n",
       "      <td>10.576703</td>\n",
       "      <td>10.189084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20183</th>\n",
       "      <td>Jamie McGinn</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.401371</td>\n",
       "      <td>4.483622</td>\n",
       "      <td>4.366652</td>\n",
       "      <td>4.008467</td>\n",
       "      <td>4.476780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20184 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name  FantasyPointsFanDuel  FantasyPointsFanDuel  \\\n",
       "0          Timo Meier                   3.2                   3.2   \n",
       "1          Martin Frk                   4.8                   4.8   \n",
       "2       Kyle Palmieri                   0.0                   0.0   \n",
       "3        Thomas Vanek                   8.5                   8.5   \n",
       "4       Kris Versteeg                  22.1                  22.1   \n",
       "...               ...                   ...                   ...   \n",
       "20179    Taylor Leier                   1.6                   1.6   \n",
       "20180  Joonas Donskoi                   0.0                   0.0   \n",
       "20181   Patrick Sharp                   0.0                   0.0   \n",
       "20182     Josh Bailey                  11.7                  11.7   \n",
       "20183    Jamie McGinn                   0.0                   0.0   \n",
       "\n",
       "       Pred_FP_all  Pred_FP_50  Pred_FP_30  Pred_FP_20  Pred_FP_10  \n",
       "0         4.589318    4.575845    4.591920    4.526959    4.153235  \n",
       "1         3.896026    3.905810    3.799460    3.824853    3.882637  \n",
       "2         9.464828    9.618115   10.613752   10.450582   11.093447  \n",
       "3         5.987462    5.989495    5.905314    6.307128    6.175032  \n",
       "4         6.858372    6.798116    6.809300    6.854523    6.390102  \n",
       "...            ...         ...         ...         ...         ...  \n",
       "20179     6.178045    6.047882    6.284507    6.235827    5.942053  \n",
       "20180     6.988086    6.787917    6.698339    6.826358    6.923340  \n",
       "20181     3.755407    3.394232    2.919445    3.353604    3.599713  \n",
       "20182     9.769311    9.575595    9.769985   10.576703   10.189084  \n",
       "20183     4.401371    4.483622    4.366652    4.008467    4.476780  \n",
       "\n",
       "[20184 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf[['Name', 'FantasyPointsFanDuel', 'Pred_FP_all', 'Pred_FP_50', 'Pred_FP_30', 'Pred_FP_20', 'Pred_FP_10']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5814702d",
   "metadata": {},
   "source": [
    "## D Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ad512fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Greg\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (63) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 65250\n",
      "Testing set size: 21750\n",
      "\n",
      "Num Possible Features: 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Greg\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# needs hyperparameters\n",
    "def lgbm_mod(): return LGBMRegressor(random_state = 1, n_estimators = 1000, learning_rate = 0.01, n_jobs = -1)\n",
    "\n",
    "working_directory = 'D:/machine_learning/DFS/NHL/'\n",
    "os.chdir(working_directory)\n",
    "data_dir = 'Data/' #Where is your data located?\n",
    "etl_dir = 'Data/ETL/' #Where is your output data going?\n",
    "\n",
    "player_stats = pd.read_csv('Data/alldata_2016-2022.csv', index_col = 0) #Read In Our Main Dataset\n",
    "d_df = pd.read_csv(etl_dir + 'd_stats.csv', index_col = 0)\n",
    "\n",
    "# ordinal encode HomeorAway column\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "encoder = OrdinalEncoder()\n",
    "d_df['HomeOrAway'] = encoder.fit_transform(d_df['HomeOrAway'].to_numpy().reshape(-1, 1))\n",
    "\n",
    "d_df = d_df.rename(columns={'Team_x' : 'Team'})\n",
    "\n",
    "# convert date from object dtype to datetime\n",
    "d_df['Date'] = pd.to_datetime(d_df['Date'], format = '%Y%m%d')\n",
    "d_df['Date'] = d_df['Date'].dt.strftime('%Y%m%d')\n",
    "\n",
    "#D DK PTS Rank For The Given Season & Date Pair\n",
    "d_df['Act_D_FPRank'] = d_df.groupby(['Season','Date'])['FantasyPointsFanDuel'].rank(method='min', ascending = False)\n",
    "\n",
    "#Columns We Want To Add To Dataset\n",
    "keep_cols = ['Season','Date','Name','Act_D_FPRank']\n",
    "\n",
    "#Make sure we have no duplicated columns or infinity errors\n",
    "d_df = d_df.loc[:,~d_df.columns.duplicated()]\n",
    "d_df= d_df.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "#Columns We Can't Include In Our Features Datasets\n",
    "dcols = ['TeamID', 'PlayerID', 'Team', 'Position', 'Games', 'Started', \n",
    "         'Goals', 'Assists', 'Points', 'PlusMinus', 'HatTricks',\n",
    "       'PenaltyMinutes', 'PowerPlayGoals', 'ShortHandedGoals', 'ShotsOnGoal',\n",
    "       'Blocks',\n",
    "       'Month', 'Year'\n",
    "]\n",
    "\n",
    "\n",
    "# g_vs_act.drop_duplicates(subset=['Player', 'Date'], keep='first', inplace = True, ignore_index = True)\n",
    "\n",
    "X = d_df.drop(dcols, axis = 1)\n",
    "Y = d_df['FantasyPointsFanDuel']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Create Training and Testing DataSets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.25, random_state=42)\n",
    "\n",
    "X_train.reset_index(inplace = True, drop=True)\n",
    "X_test.reset_index(inplace = True, drop=True)\n",
    "Y_train.reset_index(inplace = True, drop=True)\n",
    "Y_test.reset_index(inplace = True, drop=True)\n",
    "\n",
    "print('Training set size:', len(X_train))\n",
    "print('Testing set size:', len(X_test))\n",
    "\n",
    "pred_df = pd.concat([X_test, Y_test], axis = 1)\n",
    "\n",
    "more_dcols = ['Season', 'Date', 'Name', 'Opponent', 'FantasyPointsFanDuel', 'Act_D_FPRank']\n",
    "\n",
    "X_train.drop(more_dcols, axis = 1, inplace = True)\n",
    "X_test.drop(more_dcols, axis = 1, inplace = True)\n",
    "\n",
    "# dump non-scaled train df for external scaling to work\n",
    "filename = 'scalers/d_X_train.pkl'\n",
    "joblib.dump(X_train, filename)\n",
    "\n",
    "# Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "d_scaler = StandardScaler().fit(X_train)\n",
    "X_train = pd.DataFrame(d_scaler.transform(X_train), columns = X_train.columns)\n",
    "X_test = pd.DataFrame(d_scaler.transform(X_test), columns = X_test.columns)\n",
    "filename = 'scalers/d_scaler.pkl'\n",
    "joblib.dump(d_scaler, filename)\n",
    "\n",
    "print('\\nNum Possible Features:',len(X_train.columns.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b03f218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "possible features: ['HomeOrAway', 'GM3', 'GM_pg3', 'G3', 'G_pg3', 'A3', 'A_pg3', 'PTS3', 'PTS_pg3', 'plusminus3', 'plusminus_pg3', 'HT3', 'HT_pg3', 'PIM3', 'PIM_pg3', 'PPG3', 'PPG_pg3', 'SHG3', 'SHG_pg3', 'SOG3', 'SOG_pg3', 'BLK3', 'BLK_pg3', 'FP3', 'FP_pg3', 'GM', 'G', 'G_pg', 'A', 'A_pg', 'PTS', 'PTS_pg', 'PM', 'PM_pg', 'HT', 'HT_pg', 'PIM', 'PIM_pg', 'PPG', 'PPG_pg', 'SHG_pg', 'SOG', 'SOG_pg', 'BLK', 'BLK_pg', 'FP', 'FP_pg', 'def_G3', 'def_G_pg3', 'def_A3', 'def_A_pg3', 'def_PTS3', 'def_PTS_pg3', 'def_plusminus3', 'def_plusminus_pg3', 'def_HT3', 'def_HT_pg3', 'def_PIM3', 'def_PIM_pg3', 'def_PPG3', 'def_PPG_pg3', 'def_SHG3', 'def_SHG_pg3', 'def_SOG3', 'def_SOG_pg3', 'def_BLK3', 'def_BLK_pg3', 'def_FP3', 'def_FP_pg3', 'def_G', 'def_G_pg', 'def_A', 'def_A_pg', 'def_PTS', 'def_PTS_pg', 'def_PM', 'def_PM_pg', 'def_HT', 'def_HT_pg', 'def_PIM', 'def_PIM_pg', 'def_PPG', 'def_PPG_pg', 'def_SHG_pg', 'def_SOG', 'def_SOG_pg', 'def_BLK', 'def_BLK_pg', 'def_FP', 'def_FP_pg'] \n",
      "\n",
      "T50 features ['SOG_pg', 'FP_pg', 'BLK_pg', 'PM_pg', 'PIM_pg', 'FP3', 'def_FP3', 'SOG', 'A_pg', 'def_BLK_pg', 'BLK', 'G_pg', 'FP_pg3', 'def_SOG', 'def_SOG_pg', 'PTS_pg', 'SOG3', 'def_PM', 'FP', 'def_BLK', 'def_PIM_pg', 'def_PIM', 'def_FP_pg', 'PM', 'def_PM_pg', 'def_FP', 'PTS', 'BLK3', 'PPG_pg', 'def_A_pg', 'plusminus3', 'A', 'def_SOG3', 'PIM', 'HomeOrAway', 'def_PTS_pg', 'GM3', 'def_plusminus3', 'def_FP_pg3', 'SOG_pg3', 'def_BLK3', 'def_G_pg', 'def_G', 'BLK_pg3', 'def_A', 'G', 'PIM3', 'def_PTS', 'GM_pg3', 'A3'] \n",
      "\n",
      "T30 features ['SOG_pg', 'FP_pg', 'BLK_pg', 'PM_pg', 'FP3', 'PIM_pg', 'def_FP3', 'SOG', 'A_pg', 'G_pg', 'def_BLK_pg', 'def_SOG', 'FP_pg3', 'BLK', 'def_FP_pg', 'PPG_pg', 'def_SOG_pg', 'def_PM', 'def_PIM_pg', 'SOG3', 'PTS_pg', 'PTS', 'BLK3', 'def_BLK', 'def_PIM', 'def_PM_pg', 'def_FP', 'def_A_pg', 'def_plusminus3', 'FP'] \n",
      "\n",
      "T20 features ['SOG_pg', 'FP_pg', 'FP3', 'def_FP3', 'PM_pg', 'BLK_pg', 'PIM_pg', 'SOG3', 'SOG', 'A_pg', 'def_BLK_pg', 'BLK', 'FP_pg3', 'def_SOG', 'BLK3', 'G_pg', 'def_FP_pg', 'def_PIM_pg', 'def_PM', 'def_A_pg'] \n",
      "\n",
      "T10 features ['def_FP_pg', 'def_SOG', 'SOG_pg', 'FP_pg', 'SOG', 'BLK_pg', 'PM_pg', 'def_FP3', 'FP3', 'def_BLK_pg'] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all</td>\n",
       "      <td>4.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>4.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>4.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>4.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>4.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Features   MAE\n",
       "0      all  4.35\n",
       "1       50  4.35\n",
       "2       30  4.37\n",
       "3       20  4.37\n",
       "4       10  4.37"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" MODEL SELECTION \"\"\"\n",
    "\n",
    "model = lgbm_mod()\n",
    "\n",
    "\"\"\"                 \"\"\"\n",
    "\n",
    "#print possible features\n",
    "print('possible features:', X_train.columns.tolist(), '\\n')\n",
    "\n",
    "# Fit model, make predictions with all features\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "preds_all = model.predict(X_test)\n",
    "\n",
    "pdf = pred_df[['Season','Date','Opponent','Name','FantasyPointsFanDuel']].copy()\n",
    "\n",
    "pdf['Pred_FP_all'] = preds_all\n",
    "\n",
    "# save the initial model to disk\n",
    "filename = 'models/LGBM_models/D_model_allfeats.pkl'\n",
    "joblib.dump(model, filename) \n",
    "\n",
    "# get top 50 features\n",
    "dset = pd.DataFrame({'attr':X_train.columns.tolist(),'importance':model.feature_importances_}).sort_values(by='importance', ascending=False).reset_index(drop=True)\n",
    "attr50 = dset['attr'][0:50].tolist()\n",
    "\n",
    "# Using Top 50 Features, Find Top 30 Features\n",
    "model.fit(X_train[attr50], Y_train)\n",
    "dset = pd.DataFrame({'attr':X_train[attr50].columns.tolist(),'importance':model.feature_importances_}).sort_values(by='importance', ascending=False).reset_index(drop=True)\n",
    "attr30 = dset['attr'][0:30].tolist()\n",
    "\n",
    "# Using Top 30 Features, Find Top 20 Features\n",
    "model.fit(X_train[attr30], Y_train)\n",
    "dset = pd.DataFrame({'attr':X_train[attr30].columns.tolist(),'importance':model.feature_importances_}).sort_values(by='importance', ascending=False).reset_index(drop=True)\n",
    "attr20 = dset['attr'][0:20].tolist()\n",
    "\n",
    "#Perform RFE (recursive feature elimination) using Top 20 Features, To Find Top 15\n",
    "rfe_model = RFE(model, n_features_to_select = 10)\n",
    "rfe_model.fit(X_train[attr20], Y_train)\n",
    "dset = pd.DataFrame({'attr':X_train[attr20].columns.tolist(),'importance':rfe_model.ranking_}).sort_values(by='importance', ascending=False).reset_index(drop=True)\n",
    "cols10= dset[dset['importance']==1]['attr'].tolist()\n",
    "\n",
    "print('T50 features', attr50, '\\n')\n",
    "print('T30 features', attr30, '\\n')\n",
    "print('T20 features', attr20, '\\n')\n",
    "print('T10 features',cols10, '\\n')\n",
    "\n",
    "model.fit(X_train[attr50], Y_train)\n",
    "preds50 = model.predict(X_test[attr50])\n",
    "filename = 'models/LGBM_models/D_model_50feats.pkl'\n",
    "joblib.dump(model, filename) \n",
    "\n",
    "model.fit(X_train[attr30], Y_train)\n",
    "preds30 = model.predict(X_test[attr30])\n",
    "filename = 'models/LGBM_models/D_model_30feats.pkl'\n",
    "joblib.dump(model, filename) \n",
    "\n",
    "model.fit(X_train[attr20], Y_train)\n",
    "preds20 = model.predict(X_test[attr20])\n",
    "filename = 'models/LGBM_models/D_model_20feats.pkl'\n",
    "joblib.dump(model, filename) \n",
    "\n",
    "model.fit(X_train[cols10], Y_train)\n",
    "preds10 = model.predict(X_test[cols10])\n",
    "filename = 'models/LGBM_models/D_model_10feats.pkl'\n",
    "joblib.dump(model, filename) \n",
    "\n",
    "# pdf = pred_df[['Season','Week','Team','Defense','PlayerID','Name','Act_D_DKPtsRank','Act_D_DKPts']].copy()\n",
    "pdf['Pred_FP_50'] = preds50\n",
    "pdf['Pred_FP_30'] = preds30\n",
    "pdf['Pred_FP_20'] = preds20\n",
    "pdf['Pred_FP_10'] = preds10\n",
    "pdf.to_csv(etl_dir + 'd_predictions_lgbm_50_30_20_10.csv')\n",
    "\n",
    "feature_sets = ['all', '50', '30', '20', '10']\n",
    "\n",
    "mae_values = [\n",
    "    \"{:.2f}\".format(mean_absolute_error(Y_test, preds_all)),\n",
    "    \"{:.2f}\".format(mean_absolute_error(Y_test, preds50)),\n",
    "    \"{:.2f}\".format(mean_absolute_error(Y_test, preds30)),\n",
    "    \"{:.2f}\".format(mean_absolute_error(Y_test, preds20)),\n",
    "    \"{:.2f}\".format(mean_absolute_error(Y_test, preds10))\n",
    "]\n",
    "\n",
    "results_df = pd.DataFrame({'Features' : feature_sets, 'MAE' : mae_values})\n",
    "\n",
    "results_df.style.hide_index()\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4529c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>FantasyPointsFanDuel</th>\n",
       "      <th>FantasyPointsFanDuel</th>\n",
       "      <th>Pred_FP_all</th>\n",
       "      <th>Pred_FP_50</th>\n",
       "      <th>Pred_FP_30</th>\n",
       "      <th>Pred_FP_20</th>\n",
       "      <th>Pred_FP_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zach Werenski</td>\n",
       "      <td>14.4</td>\n",
       "      <td>14.4</td>\n",
       "      <td>5.3274</td>\n",
       "      <td>4.8950</td>\n",
       "      <td>4.8258</td>\n",
       "      <td>2.4314</td>\n",
       "      <td>2.3360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ian Cole</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>7.8586</td>\n",
       "      <td>7.7790</td>\n",
       "      <td>8.2474</td>\n",
       "      <td>8.7848</td>\n",
       "      <td>8.5032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Matt Irwin</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.4934</td>\n",
       "      <td>4.8826</td>\n",
       "      <td>5.2250</td>\n",
       "      <td>5.2010</td>\n",
       "      <td>4.7906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deryk Engelland</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>5.7544</td>\n",
       "      <td>5.7594</td>\n",
       "      <td>5.9944</td>\n",
       "      <td>6.8192</td>\n",
       "      <td>7.4642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MacKenzie Weegar</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.8464</td>\n",
       "      <td>4.7330</td>\n",
       "      <td>5.2606</td>\n",
       "      <td>4.1384</td>\n",
       "      <td>5.1978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21745</th>\n",
       "      <td>Brenden Dillon</td>\n",
       "      <td>6.4</td>\n",
       "      <td>6.4</td>\n",
       "      <td>7.6408</td>\n",
       "      <td>6.9542</td>\n",
       "      <td>7.2984</td>\n",
       "      <td>7.9110</td>\n",
       "      <td>6.8510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21746</th>\n",
       "      <td>Michael Stone</td>\n",
       "      <td>9.6</td>\n",
       "      <td>9.6</td>\n",
       "      <td>4.9832</td>\n",
       "      <td>4.4548</td>\n",
       "      <td>5.3800</td>\n",
       "      <td>5.1872</td>\n",
       "      <td>7.6112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21747</th>\n",
       "      <td>Matt Dumba</td>\n",
       "      <td>11.2</td>\n",
       "      <td>11.2</td>\n",
       "      <td>9.0702</td>\n",
       "      <td>9.3572</td>\n",
       "      <td>9.3330</td>\n",
       "      <td>9.2604</td>\n",
       "      <td>9.9840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21748</th>\n",
       "      <td>Kurtis MacDermid</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.3426</td>\n",
       "      <td>3.4786</td>\n",
       "      <td>3.9302</td>\n",
       "      <td>4.0714</td>\n",
       "      <td>4.2632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21749</th>\n",
       "      <td>Erik Gustafsson</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2992</td>\n",
       "      <td>0.5258</td>\n",
       "      <td>0.7006</td>\n",
       "      <td>0.6792</td>\n",
       "      <td>1.4056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21750 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Name  FantasyPointsFanDuel  FantasyPointsFanDuel  \\\n",
       "0         Zach Werenski                  14.4                  14.4   \n",
       "1              Ian Cole                   4.8                   4.8   \n",
       "2            Matt Irwin                   4.8                   4.8   \n",
       "3       Deryk Engelland                   1.6                   1.6   \n",
       "4      MacKenzie Weegar                   3.2                   3.2   \n",
       "...                 ...                   ...                   ...   \n",
       "21745    Brenden Dillon                   6.4                   6.4   \n",
       "21746     Michael Stone                   9.6                   9.6   \n",
       "21747        Matt Dumba                  11.2                  11.2   \n",
       "21748  Kurtis MacDermid                   1.6                   1.6   \n",
       "21749   Erik Gustafsson                   0.0                   0.0   \n",
       "\n",
       "       Pred_FP_all  Pred_FP_50  Pred_FP_30  Pred_FP_20  Pred_FP_10  \n",
       "0           5.3274      4.8950      4.8258      2.4314      2.3360  \n",
       "1           7.8586      7.7790      8.2474      8.7848      8.5032  \n",
       "2           4.4934      4.8826      5.2250      5.2010      4.7906  \n",
       "3           5.7544      5.7594      5.9944      6.8192      7.4642  \n",
       "4           4.8464      4.7330      5.2606      4.1384      5.1978  \n",
       "...            ...         ...         ...         ...         ...  \n",
       "21745       7.6408      6.9542      7.2984      7.9110      6.8510  \n",
       "21746       4.9832      4.4548      5.3800      5.1872      7.6112  \n",
       "21747       9.0702      9.3572      9.3330      9.2604      9.9840  \n",
       "21748       3.3426      3.4786      3.9302      4.0714      4.2632  \n",
       "21749       0.2992      0.5258      0.7006      0.6792      1.4056  \n",
       "\n",
       "[21750 rows x 8 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf[['Name', 'FantasyPointsFanDuel', 'Pred_FP_all', 'Pred_FP_50', 'Pred_FP_30', 'Pred_FP_20', 'Pred_FP_10']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ec2c90",
   "metadata": {},
   "source": [
    "## G Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e27388cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Greg\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (63) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 19128\n",
      "Testing set size: 6377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Greg\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# needs hyperparameters\n",
    "def lgbm_mod(): return LGBMRegressor(random_state = 1, n_estimators = 1000, learning_rate = 0.01, n_jobs = -1)\n",
    "\n",
    "working_directory = 'D:/machine_learning/DFS/NHL/'\n",
    "os.chdir(working_directory)\n",
    "data_dir = 'Data/' #Where is your data located?\n",
    "etl_dir = 'Data/ETL/' #Where is your output data going?\n",
    "\n",
    "player_stats = pd.read_csv('Data/alldata_2016-2022.csv', index_col = 0) #Read In Our Main Dataset\n",
    "g_df = pd.read_csv(etl_dir + 'g_stats.csv', index_col = 0)\n",
    "\n",
    "# ordinal encode HomeorAway column\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "encoder = OrdinalEncoder()\n",
    "g_df['HomeOrAway'] = encoder.fit_transform(g_df['HomeOrAway'].to_numpy().reshape(-1, 1))\n",
    "\n",
    "g_df = g_df.rename(columns={'Team_x' : 'Team'})\n",
    "\n",
    "# convert date from object dtype to datetime\n",
    "g_df['Date'] = pd.to_datetime(g_df['Date'], format = '%Y%m%d')\n",
    "g_df['Date'] = g_df['Date'].dt.strftime('%Y%m%d')\n",
    "\n",
    "#G DK PTS Rank For The Given Season & Date Pair\n",
    "g_df['Act_G_FPRank'] = g_df.groupby(['Season','Date'])['FantasyPointsFanDuel'].rank(method='min', ascending = False)\n",
    "\n",
    "#Columns We Want To Add To Dataset\n",
    "keep_cols = ['Season','Date','Name','Act_G_FPRank']\n",
    "\n",
    "#Make sure we have no duplicated columns or infinity errors\n",
    "g_df = g_df.loc[:,~g_df.columns.duplicated()]\n",
    "g_df= g_df.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "#Columns We Can't Include In Our Features Datasets\n",
    "dcols = [\n",
    "     'TeamID',\n",
    "     'PlayerID',\n",
    "     'Team',\n",
    "     'Position',\n",
    "     'Games',\n",
    "     'Started',\n",
    "     'GoaltendingWins',\n",
    "     'GoaltendingLosses',\n",
    "     'GoaltendingOvertimeLosses',\n",
    "     'GoaltendingShotsAgainst',\n",
    "     'GoaltendingGoalsAgainst',\n",
    "     'GoaltendingSaves',\n",
    "     'GoaltendingShutouts',\n",
    "     'GoaltendingGoalsAgainstAverage',\n",
    "     'GoaltendingSavePercentage',\n",
    "     'GoaltendingMinutes',\n",
    "     'Month',\n",
    "     'Year',\n",
    "    ]\n",
    "\n",
    "\n",
    "# g_vs_act.drop_duplicates(subset=['Player', 'Date'], keep='first', inplace = True, ignore_index = True)\n",
    "\n",
    "X = g_df.drop(dcols, axis = 1)\n",
    "Y = g_df['FantasyPointsFanDuel']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Create Training and Testing DataSets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.25, random_state=42)\n",
    "\n",
    "X_train.reset_index(inplace = True, drop=True)\n",
    "X_test.reset_index(inplace = True, drop=True)\n",
    "Y_train.reset_index(inplace = True, drop=True)\n",
    "Y_test.reset_index(inplace = True, drop=True)\n",
    "\n",
    "# # get nonzero entries for GTGAA_pg3\n",
    "# X_test_nz = X_test.loc[X_test['GTGAA_pg3'] != 0]\n",
    "\n",
    "# # get indices of dropped rows\n",
    "# dropped_row_idx = list(X_test.index[~X_test.index.isin(X_test_nz.index) == False])\n",
    "\n",
    "# # drop Y_test entries that were dropped from X test\n",
    "# Y_test = Y_test.iloc[dropped_row_idx]\n",
    "\n",
    "# # reassign X_test and reset indices\n",
    "# X_test = X_test_nz\n",
    "# X_test.reset_index(inplace = True, drop=True)\n",
    "# Y_test.reset_index(inplace = True, drop=True)\n",
    "\n",
    "print('Training set size:', len(X_train))\n",
    "print('Testing set size:', len(X_test))\n",
    "\n",
    "pred_df = pd.concat([X_test, Y_test], axis = 1)\n",
    "\n",
    "more_dcols = ['Season', 'Date', 'Name', 'Opponent', 'FantasyPointsFanDuel', 'Act_G_FPRank']\n",
    "\n",
    "X_train.drop(more_dcols, axis = 1, inplace = True)\n",
    "X_test.drop(more_dcols, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dd0199a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Num Possible Features: 95\n"
     ]
    }
   ],
   "source": [
    "# dump non-scaled train df for external scaling to work\n",
    "filename = 'scalers/g_X_train.pkl'\n",
    "joblib.dump(X_train, filename)\n",
    "\n",
    "# Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "g_scaler = StandardScaler().fit(X_train)\n",
    "X_train = pd.DataFrame(g_scaler.transform(X_train), columns = X_train.columns)\n",
    "X_test = pd.DataFrame(g_scaler.transform(X_test), columns = X_test.columns)\n",
    "filename = 'scalers/g_scaler.pkl'\n",
    "joblib.dump(g_scaler, filename)\n",
    "\n",
    "print('\\nNum Possible Features:',len(X_train.columns.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "932725b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "possible features: ['HomeOrAway', 'GM3', 'GM_pg3', 'GTW3', 'GTW_pg3', 'GTL3', 'GTL_pg3', 'GTOTL3', 'GTOTL_pg3', 'GTSA3', 'GTSA_pg3', 'GTGA3', 'GTGA_pg3', 'GTS3', 'GTS_pg3', 'GTSO3', 'GTSO_pg3', 'GTGAA_pg3', 'GTSP_pg3', 'GTM3', 'GTM_pg3', 'FP3', 'FP_pg3', 'WP3', 'SPM3', 'GM', 'GTW', 'GTW_pg', 'GTL', 'GTL_pg', 'GTOTL', 'GTOTL_pg', 'GTSA', 'GTSA_pg', 'GTGA', 'GTGA_pg', 'GTS', 'GTS_pg', 'GTSO', 'GTSO_pg', 'GTGAA_pg', 'GTSP_pg', 'GTM', 'GTM_pg', 'FP', 'FP_pg', 'WP', 'SPM', 'def_GM3', 'def_GM_pg3', 'def_GTW3', 'def_GTW_pg3', 'def_GTL3', 'def_GTL_pg3', 'def_GTOTL3', 'def_GTOTL_pg3', 'def_GTSA3', 'def_GTSA_pg3', 'def_GTGA3', 'def_GTGA_pg3', 'def_GTS3', 'def_GTS_pg3', 'def_GTSO3', 'def_GTSO_pg3', 'def_GTGAA_pg3', 'def_GTSP_pg3', 'def_GTM3', 'def_GTM_pg3', 'def_FP3', 'def_FP_pg3', 'def_WP3', 'def_SPM3', 'def_GM', 'def_GTW', 'def_GTW_pg', 'def_GTL', 'def_GTL_pg', 'def_GTOTL', 'def_GTOTL_pg', 'def_GTSA', 'def_GTSA_pg', 'def_GTGA', 'def_GTGA_pg', 'def_GTS', 'def_GTS_pg', 'def_GTSO', 'def_GTSO_pg', 'def_GTGAA_pg', 'def_GTSP_pg', 'def_GTM', 'def_GTM_pg', 'def_FP', 'def_FP_pg', 'def_WP', 'def_SPM'] \n",
      "\n",
      "T50 features ['SPM', 'def_SPM', 'FP_pg', 'GTSP_pg', 'GTM3', 'def_GTGAA_pg', 'GTSP_pg3', 'GTM_pg', 'GTGAA_pg', 'def_SPM3', 'FP3', 'GTGA_pg', 'SPM3', 'GTW_pg', 'def_FP3', 'GTL_pg', 'def_GTGAA_pg3', 'GTGAA_pg3', 'def_WP', 'def_GTL_pg', 'def_GTSO_pg', 'def_GTGA_pg', 'def_GTGA', 'def_GTSP_pg', 'GTOTL_pg', 'GTSO_pg', 'def_GTSP_pg3', 'def_GTOTL_pg', 'WP', 'def_FP_pg', 'def_GTM_pg', 'def_GTW_pg', 'GTGA', 'FP', 'def_FP', 'def_GTSA_pg', 'GTSA3', 'GTS_pg', 'GTM_pg3', 'GTSA_pg', 'def_GTS_pg', 'def_GTSA', 'def_GTM', 'GTS3', 'def_GTM3', 'def_GTSA3', 'FP_pg3', 'GTW', 'def_GM', 'GTM'] \n",
      "\n",
      "T30 features ['SPM', 'def_SPM', 'GTSP_pg', 'def_SPM3', 'GTW_pg', 'FP_pg', 'def_WP', 'SPM3', 'def_GTGAA_pg', 'GTGAA_pg', 'def_FP3', 'GTGAA_pg3', 'def_GTGAA_pg3', 'FP3', 'GTL_pg', 'GTM3', 'GTGA_pg', 'GTM_pg', 'GTSP_pg3', 'def_GTSO_pg', 'def_GTGA_pg', 'GTOTL_pg', 'def_GTL_pg', 'GTSA3', 'def_FP_pg', 'WP', 'GTSO_pg', 'def_GTSA3', 'def_GTOTL_pg', 'GTGA'] \n",
      "\n",
      "T20 features ['def_SPM', 'def_FP_pg', 'GTGA', 'SPM', 'def_FP3', 'FP_pg', 'GTSP_pg', 'GTM3', 'GTM_pg', 'FP3', 'def_GTGA_pg', 'def_WP', 'SPM3', 'def_GTGAA_pg', 'GTL_pg', 'def_GTGAA_pg3', 'def_SPM3', 'def_GTL_pg', 'def_GTSA3', 'GTGAA_pg'] \n",
      "\n",
      "T10 features ['SPM3', 'def_SPM', 'def_WP', 'def_FP_pg', 'FP3', 'GTM_pg', 'GTSP_pg', 'def_FP3', 'SPM', 'def_GTGA_pg'] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>9.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>9.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>9.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>9.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Features   MAE\n",
       "0      all  9.67\n",
       "1       50  9.72\n",
       "2       30  9.74\n",
       "3       20  9.78\n",
       "4       10  9.80"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" MODEL SELECTION \"\"\"\n",
    "\n",
    "model = lgbm_mod()\n",
    "\n",
    "\"\"\"                 \"\"\"\n",
    "\n",
    "#print possible features\n",
    "print('possible features:', X_train.columns.tolist(), '\\n')\n",
    "\n",
    "# Fit model, make predictions with all features\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "preds_all = model.predict(X_test)\n",
    "\n",
    "pdf = pred_df[['Season','Date','Opponent','Name','FantasyPointsFanDuel']].copy()\n",
    "\n",
    "pdf['Pred_FP_all'] = preds_all\n",
    "\n",
    "# save the initial model to disk\n",
    "filename = 'models/LGBM_models/G_model_allfeats.pkl'\n",
    "joblib.dump(model, filename) \n",
    "\n",
    "# get top 50 features\n",
    "dset = pd.DataFrame({'attr':X_train.columns.tolist(),'importance':model.feature_importances_}).sort_values(by='importance', ascending=False).reset_index(drop=True)\n",
    "attr50 = dset['attr'][0:50].tolist()\n",
    "\n",
    "# Using Top 50 Features, Find Top 30 Features\n",
    "model.fit(X_train[attr50], Y_train)\n",
    "dset = pd.DataFrame({'attr':X_train[attr50].columns.tolist(),'importance':model.feature_importances_}).sort_values(by='importance', ascending=False).reset_index(drop=True)\n",
    "attr30 = dset['attr'][0:30].tolist()\n",
    "\n",
    "# Using Top 30 Features, Find Top 20 Features\n",
    "model.fit(X_train[attr30], Y_train)\n",
    "dset = pd.DataFrame({'attr':X_train[attr30].columns.tolist(),'importance':model.feature_importances_}).sort_values(by='importance', ascending=False).reset_index(drop=True)\n",
    "attr20 = dset['attr'][0:20].tolist()\n",
    "\n",
    "#Perform RFE (recursive feature elimination) using Top 20 Features, To Find Top 15\n",
    "rfe_model = RFE(model, n_features_to_select = 10)\n",
    "rfe_model.fit(X_train[attr20], Y_train)\n",
    "dset = pd.DataFrame({'attr':X_train[attr20].columns.tolist(),'importance':rfe_model.ranking_}).sort_values(by='importance', ascending=False).reset_index(drop=True)\n",
    "cols10= dset[dset['importance']==1]['attr'].tolist()\n",
    "\n",
    "print('T50 features', attr50, '\\n')\n",
    "print('T30 features', attr30, '\\n')\n",
    "print('T20 features', attr20, '\\n')\n",
    "print('T10 features',cols10, '\\n')\n",
    "\n",
    "model.fit(X_train[attr50], Y_train)\n",
    "preds50 = model.predict(X_test[attr50])\n",
    "filename = 'models/LGBM_models/G_model_50feats.pkl'\n",
    "joblib.dump(model, filename) \n",
    "\n",
    "model.fit(X_train[attr30], Y_train)\n",
    "preds30 = model.predict(X_test[attr30])\n",
    "filename = 'models/LGBM_models/G_model_30feats.pkl'\n",
    "joblib.dump(model, filename) \n",
    "\n",
    "model.fit(X_train[attr20], Y_train)\n",
    "preds20 = model.predict(X_test[attr20])\n",
    "filename = 'models/LGBM_models/G_model_20feats.pkl'\n",
    "joblib.dump(model, filename) \n",
    "\n",
    "model.fit(X_train[cols10], Y_train)\n",
    "preds10 = model.predict(X_test[cols10])\n",
    "filename = 'models/LGBM_models/G_model_10feats.pkl'\n",
    "joblib.dump(model, filename) \n",
    "\n",
    "# pdf = pred_df[['Season','Week','Team','Defense','PlayerID','Name','Act_G_DKPtsRank','Act_G_DKPts']].copy()\n",
    "pdf['Pred_FP_50'] = preds50\n",
    "pdf['Pred_FP_30'] = preds30\n",
    "pdf['Pred_FP_20'] = preds20\n",
    "pdf['Pred_FP_10'] = preds10\n",
    "pdf.to_csv(etl_dir + 'g_predictions_lgbm_50_30_20_10.csv')\n",
    "\n",
    "feature_sets = ['all', '50', '30', '20', '10']\n",
    "\n",
    "mae_values = [\n",
    "    \"{:.2f}\".format(mean_absolute_error(Y_test, preds_all)),\n",
    "    \"{:.2f}\".format(mean_absolute_error(Y_test, preds50)),\n",
    "    \"{:.2f}\".format(mean_absolute_error(Y_test, preds30)),\n",
    "    \"{:.2f}\".format(mean_absolute_error(Y_test, preds20)),\n",
    "    \"{:.2f}\".format(mean_absolute_error(Y_test, preds10))\n",
    "]\n",
    "\n",
    "results_df = pd.DataFrame({'Features' : feature_sets, 'MAE' : mae_values})\n",
    "\n",
    "results_df.style.hide_index()\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6846bac9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>FantasyPointsFanDuel</th>\n",
       "      <th>FantasyPointsFanDuel</th>\n",
       "      <th>Pred_FP_all</th>\n",
       "      <th>Pred_FP_50</th>\n",
       "      <th>Pred_FP_30</th>\n",
       "      <th>Pred_FP_20</th>\n",
       "      <th>Pred_FP_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Frederik Andersen</td>\n",
       "      <td>27.2</td>\n",
       "      <td>27.2</td>\n",
       "      <td>14.590631</td>\n",
       "      <td>15.367259</td>\n",
       "      <td>14.448247</td>\n",
       "      <td>13.292447</td>\n",
       "      <td>15.565027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Michal Neuvirth</td>\n",
       "      <td>9.6</td>\n",
       "      <td>9.6</td>\n",
       "      <td>6.249915</td>\n",
       "      <td>7.124373</td>\n",
       "      <td>5.425216</td>\n",
       "      <td>5.712783</td>\n",
       "      <td>5.874368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Martin Jones</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.092011</td>\n",
       "      <td>8.326732</td>\n",
       "      <td>11.790089</td>\n",
       "      <td>11.055085</td>\n",
       "      <td>11.037476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Martin Jones</td>\n",
       "      <td>32.8</td>\n",
       "      <td>32.8</td>\n",
       "      <td>14.394197</td>\n",
       "      <td>14.734338</td>\n",
       "      <td>13.565939</td>\n",
       "      <td>14.528435</td>\n",
       "      <td>16.245499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jimmy Howard</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>11.254156</td>\n",
       "      <td>9.778327</td>\n",
       "      <td>10.438184</td>\n",
       "      <td>11.232283</td>\n",
       "      <td>11.939451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6372</th>\n",
       "      <td>Anton Forsberg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.873817</td>\n",
       "      <td>2.878365</td>\n",
       "      <td>2.798817</td>\n",
       "      <td>2.836061</td>\n",
       "      <td>2.770586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6373</th>\n",
       "      <td>Keith Kinkaid</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.785185</td>\n",
       "      <td>3.094633</td>\n",
       "      <td>3.362242</td>\n",
       "      <td>3.614268</td>\n",
       "      <td>3.102860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6374</th>\n",
       "      <td>Antti Raanta</td>\n",
       "      <td>21.6</td>\n",
       "      <td>21.6</td>\n",
       "      <td>6.710030</td>\n",
       "      <td>5.310932</td>\n",
       "      <td>5.613977</td>\n",
       "      <td>5.539519</td>\n",
       "      <td>5.591537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6375</th>\n",
       "      <td>Philipp Grubauer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.608029</td>\n",
       "      <td>5.740670</td>\n",
       "      <td>5.357241</td>\n",
       "      <td>5.227709</td>\n",
       "      <td>5.512778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6376</th>\n",
       "      <td>Juuse Saros</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.423493</td>\n",
       "      <td>5.225277</td>\n",
       "      <td>4.804132</td>\n",
       "      <td>5.564262</td>\n",
       "      <td>4.483465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6377 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Name  FantasyPointsFanDuel  FantasyPointsFanDuel  \\\n",
       "0     Frederik Andersen                  27.2                  27.2   \n",
       "1       Michal Neuvirth                   9.6                   9.6   \n",
       "2          Martin Jones                   0.0                   0.0   \n",
       "3          Martin Jones                  32.8                  32.8   \n",
       "4          Jimmy Howard                  36.0                  36.0   \n",
       "...                 ...                   ...                   ...   \n",
       "6372     Anton Forsberg                   0.0                   0.0   \n",
       "6373      Keith Kinkaid                   0.0                   0.0   \n",
       "6374       Antti Raanta                  21.6                  21.6   \n",
       "6375   Philipp Grubauer                   0.0                   0.0   \n",
       "6376        Juuse Saros                   0.0                   0.0   \n",
       "\n",
       "      Pred_FP_all  Pred_FP_50  Pred_FP_30  Pred_FP_20  Pred_FP_10  \n",
       "0       14.590631   15.367259   14.448247   13.292447   15.565027  \n",
       "1        6.249915    7.124373    5.425216    5.712783    5.874368  \n",
       "2       10.092011    8.326732   11.790089   11.055085   11.037476  \n",
       "3       14.394197   14.734338   13.565939   14.528435   16.245499  \n",
       "4       11.254156    9.778327   10.438184   11.232283   11.939451  \n",
       "...           ...         ...         ...         ...         ...  \n",
       "6372     2.873817    2.878365    2.798817    2.836061    2.770586  \n",
       "6373     2.785185    3.094633    3.362242    3.614268    3.102860  \n",
       "6374     6.710030    5.310932    5.613977    5.539519    5.591537  \n",
       "6375     5.608029    5.740670    5.357241    5.227709    5.512778  \n",
       "6376     4.423493    5.225277    4.804132    5.564262    4.483465  \n",
       "\n",
       "[6377 rows x 8 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf[['Name', 'FantasyPointsFanDuel', 'Pred_FP_all', 'Pred_FP_50', 'Pred_FP_30', 'Pred_FP_20', 'Pred_FP_10']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
